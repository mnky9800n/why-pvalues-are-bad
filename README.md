# Why *p*-values are not as useful as we might think
A repository of links to papers that articulate why *p*-values don't tell us what most people think they tell us.

Sorry Sir Ronald Fisher, I love you, but I don't love your *p*-values.

Quotes taken from the links below just in case you like it **spicy**:

>The most important task before us in developing statistical science is to
demolish the P-value culture, which has taken root to a frightening extent
in many areas of both pure and applied science, and technology. (Nelder,
1999, p. 261)

>My personal view is that p-values should be relegated to the scrap heap
and not considered by those who wish to think and act coherently.
(Lindley, 1999, p. 75)

>"It is extraordinarily difficult to find a
 statistician who argues explicitly in favor of the
 retention of significance tests ..." (Oakes, 1986)
 
>The implication of hypothesis testing- that
there can always be a simple "yes" or "no" answer as the
fundamental result from a medical study-is clearly false and used
in this way hypothesis testing is of limited value. (Gardner, 1986)

## Arguments against *p*-values

1. **Why P Values Are Not a Useful Measure of Evidence in Statistical Significance Testing** - https://journals.sagepub.com/doi/pdf/10.1177/0959354307086923
2. **P values are only an index to evidence: 20th- vs. 21st-century statistical science** - https://www.jstor.org/stable/pdf/43495188.pdf
3. **Statistical reform in medicine, psychology and ecology** - https://www.sciencedirect.com/science/article/pii/S1053535704000940
4. **Confidence intervals rather than P values: estimation rather than hypothesis testing** - https://www.bmj.com/content/bmj/292/6522/746.full.pdf

## Why *p*-values are alright

1. feel free to make a pull request to add stuff here.
